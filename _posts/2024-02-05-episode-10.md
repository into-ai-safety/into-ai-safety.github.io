---
title: "HACKATHON: Evals November 2023 (2)"
date: 2024-02-05T00:00:00-07:00
categories:
  - Episode
  - Hackathon
tags:
  - Evals
  - Apart
  - Ep.10
---

Join our hackathon group for the second episode in the Evals November 2023 Hackathon subseries. In this episode, we solidify our goals for the hackathon after some preliminary experimentation and ideation.
<audio controls>
<source src="https://into-ai-safety.github.io/assets\audio\into-ai-safety_ep.10.mp3" type="audio/mp3">
</audio>

Check out Stellaric's <a href="https://stellaric.pw/" target="_blank" rel="noreferrer noopener">website</a>, or follow them on <a href="https://twitter.com/stellaricpw" target="_blank" rel="noreferrer noopener">Twitter</a>.

### Chapters

01:53 - Meeting starts<br>
05:05 - Pitch: extension of locked models<br>
23:23 - Pitch: retroactive holdout datasets<br>
34:04 - Preliminary results<br>
37:44 - Next steps<br>
42:55 - Recap


### Links

Links to all articles/papers which are mentioned throughout the episode can be found below, in order of their appearance.
- <a href="https://github.com/LRudL/evalugator" target="_blank" rel="noreferrer noopener">Evalugator</a> library
- <a href="https://www.alignmentforum.org/posts/rZs6ddqNnW8LXuJqA/password-locked-models-a-stress-case-for-capabilities" target="_blank" rel="noreferrer noopener">Password Locked Models</a> blogpost
- <a href="https://arxiv.org/abs/2109.07958" target="_blank" rel="noreferrer noopener">TruthfulQA: Measuring How Models Mimic Human Falsehoods</a>
- <a href="https://aclanthology.org/P02-1040.pdf">BLEU: a Method for Automatic Evaluation of Machine Translation</a>
- <a href="https://arxiv.org/abs/1905.10044" target="_blank" rel="noreferrer noopener">BoolQ: Exploring the Surprising Difficulty of Natural Yes/No Questions</a>
- <a href="https://arxiv.org/abs/2310.16789" target="_blank" rel="noreferrer noopener">Detecting Pretraining Data from Large Language Models</a>

<!-- end of the list -->
